{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the performance of ensemble with varying datasets and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, make sure to run the `ensemble_roc.py` script first to generate the `ensemble_roc.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# modify this to set up directory:\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "model = \"renset56\"\n",
    "attack_list = [\"losstraj\", \"reference\", \"lira\", \"calibration\"]\n",
    "dataset_list = [\"cifar10\", \"cifar100\", \"cinic10\", \"texas100\", \"purchase100\"]\n",
    "# dataset_list = [\"cinic10\"]\n",
    "ensemble_method_list = [\"union\", \"intersection\", \"majority_vote\"]\n",
    "seeds = [0, 1, 2, 3, 4, 5]\n",
    "path_to_data = f'{DATA_DIR}/miae_standard_exp'\n",
    "path_to_save_result = f'{path_to_data}/ensemble_roc_base_sd_1/performance_comp/{model}'\n",
    "if os.path.exists(path_to_save_result) == False:\n",
    "    os.makedirs(path_to_save_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_ensemble_perf(dataset, num_seed, ensemble_method, path_to_data):\n",
    "    if dataset == \"texas100\" or dataset == \"purchase100\":\n",
    "        path_to_df = f\"{path_to_data}/ensemble_roc_base_sd_1/mlp_for_texas_purchase/{dataset}/{num_seed}_seeds/{ensemble_method}\"\n",
    "    else:\n",
    "        path_to_df = f\"{path_to_data}/ensemble_roc_base_sd_1/{model}/{dataset}/{num_seed}_seeds/{ensemble_method}\"\n",
    "    df = pd.read_pickle(f\"{path_to_df}/ensemble_perf.pkl\")\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert roc and acc of multiple dataset to a csv table."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from copy import deepcopy\n",
    "perf_union_df_dict = {}\n",
    "perf_intersection_df_dict = {}\n",
    "perf_majority_vote_df_dict = {}\n",
    "# for num_seed in range(2, len(seeds)+1):\n",
    "for num_seed in [6]:\n",
    "    # merge to a single dataframe\n",
    "    # rows: Ensemble Level, losstraj, reference, lira, calibration, dataset, ensemble_method, auc, acc, tpr@0.001fpr, fpr\n",
    "\n",
    "    # note that when fpr != 0.0001, then the tpr and fpr are calculated not with interpolation, but sample from true data point\n",
    "    # on the roc curve that is closest to fpr = 0.0001\n",
    "\n",
    "    for ensemble in ensemble_method_list:\n",
    "        perf_df = pd.DataFrame(columns=[\"Ensemble Level\", \"losstraj\", \"reference\", \"lira\", \"calibration\", \"dataset\", \"AUC\", \"ACC\", \"TPR@0.001FPR\", \"FPR\"]\n",
    "                               ).astype({\"AUC\": float, \"ACC\": float, \"losstraj\": bool, \"reference\": bool, \"lira\": bool, \"calibration\": bool})\n",
    "        for dataset in dataset_list:\n",
    "            df = load_ensemble_perf(dataset, num_seed, ensemble, path_to_data)\n",
    "            for _, row in df.iterrows():\n",
    "                ensemble_level = row[\"Ensemble Level\"]\n",
    "                auc = row[\"AUC\"]\n",
    "                acc = row[\"ACC\"]\n",
    "                attack_names = row[\"Attack\"].split(\"_\")\n",
    "                losstraj = \"losstraj\" in attack_names\n",
    "                reference = \"reference\" in attack_names\n",
    "                lira = \"lira\" in attack_names\n",
    "                calibration = \"calibration\" in attack_names\n",
    "                new_entry = {\"Ensemble Level\": ensemble_level, \"losstraj\": losstraj, \"reference\": reference, \"lira\": lira, \"calibration\": calibration, \"dataset\": dataset, \n",
    "                             \"AUC\": auc, \"ACC\": acc, \"TPR@0.001FPR\": row[\"TPR@0.001FPR\"], \"FPR\": row[\"FPR\"]}\n",
    "                new_entry = pd.DataFrame([new_entry]).astype(perf_df.dtypes.to_dict())\n",
    "                perf_df = pd.concat([perf_df, new_entry], ignore_index=True)\n",
    "\n",
    "        # save to csv\n",
    "        perf_df.to_csv(f\"{path_to_save_result}/{ensemble}_ensemble_{num_seed}seeds_perf.csv\", index=False)\n",
    "        if ensemble == \"union\":\n",
    "            perf_union_df_dict[num_seed] = deepcopy(perf_df)\n",
    "        elif ensemble == \"intersection\":\n",
    "            perf_intersection_df_dict[num_seed] = deepcopy(perf_df)\n",
    "        elif ensemble == \"majority_vote\":\n",
    "            perf_majority_vote_df_dict[num_seed] = deepcopy(perf_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np  # Make sure to import numpy for polyfit and poly1d\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "# plot auc and acc of 4-attack_multi_attck ensemble from each dataset for different number of instances\n",
    "for y_axis, ensemble_method in itertools.product([\"AUC\", \"ACC\", \"TPR@0.001FPR\"], [\"union\", \"intersection\"]):\n",
    "    fig, ax = plt.subplots()\n",
    "    temp_df = pd.DataFrame(columns=[\"dataset\", \"num_seed\", y_axis]).astype({y_axis: float, \"num_seed\": int})\n",
    "    for dataset in dataset_list:\n",
    "        for num_seed in range(2, len(seeds)+1):\n",
    "            # set a pointer to the correct dataframe\n",
    "            perf_df_dict = perf_union_df_dict if ensemble_method == \"union\" else perf_intersection_df_dict\n",
    "            perf_df = perf_df_dict[num_seed]\n",
    "            perf_df = perf_df[\n",
    "                (perf_df[\"dataset\"] == dataset) & \n",
    "                (perf_df[\"losstraj\"] == True) & \n",
    "                (perf_df[\"reference\"] == True) & \n",
    "                (perf_df[\"lira\"] == True) & \n",
    "                (perf_df[\"calibration\"] == True)\n",
    "            ]\n",
    "            # make sure there is only one row\n",
    "            if len(perf_df) != 1:\n",
    "                # collect the names for the attacks\n",
    "                attack_names = []\n",
    "                for _, row in perf_df.iterrows():\n",
    "                    print(row)\n",
    "                # print(f\"More than one row for {dataset} {num_seed} seeds: {attack_names}\")\n",
    "                raise ValueError(f\"More than one row for {dataset} {num_seed} seeds\")\n",
    "            y_val = perf_df[y_axis].values[0]\n",
    "            new_row = pd.DataFrame([{\"dataset\": dataset, \"num_seed\": num_seed, y_axis: y_val}])\n",
    "            temp_df = pd.concat([temp_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Plot scatter points\n",
    "    sns.scatterplot(data=temp_df, x=\"num_seed\", y=y_axis, hue=\"dataset\", ax=ax)\n",
    "    # Get the current color palette\n",
    "    palette = sns.color_palette()\n",
    "    # Get the mapping of dataset to color\n",
    "    dataset_unique = temp_df['dataset'].unique()\n",
    "    palette_dict = dict(zip(dataset_unique, palette))\n",
    "\n",
    "    # Loop over datasets and plot trend lines\n",
    "    for dataset in dataset_unique:\n",
    "        dataset_df = temp_df[temp_df['dataset'] == dataset]\n",
    "        sns.regplot(\n",
    "            data=dataset_df, x=\"num_seed\", y=y_axis, \n",
    "            scatter=False, color=palette_dict[dataset], ax=ax, label=None\n",
    "        )\n",
    "\n",
    "    ax.set_ylabel(y_axis)\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    ax.set_xlabel(\"Number of Instances\")\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles=handles[:len(dataset_unique)], labels=labels[:len(dataset_unique)], title='Dataset')\n",
    "    plt.savefig(f\"{path_to_save_result}/num_seed_vs_{y_axis}_{ensemble_method}_ensemble.pdf\", bbox_inches='tight', format='pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new csv to display the performance of ensemble with varying datasets and models."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The columns shall be:\n",
    "Ensemble_level, cifar10_auc, cifar10_acc, cifar100_auc, cifar100_acc, cinic10_auc, cinic10_acc, texas100_auc, texas100_acc, purchase100_auc, purchase100_acc\n",
    "\"\"\"\n",
    "# print out the multi-attack ensemble's entry with all attacks\n",
    "\n",
    "num_seed = 6\n",
    "# for ensemble_method in ensemble_method_list:\n",
    "for ensemble_method in ensemble_method_list:\n",
    "    result_df = pd.DataFrame(columns=[\"Ensemble_level\", \"attack\" , \"cifar10_auc\", \"cifar10_acc\", \"cifar100_auc\", \"cifar100_acc\", \"cinic10_auc\", \"cinic10_acc\", \"texas100_auc\", \"texas100_acc\", \"purchase100_auc\", \"purchase100_acc\"])\n",
    "    # handle rows for single attack\n",
    "\n",
    "    perf_df = perf_union_df_dict[num_seed] if ensemble_method == \"union\" else perf_intersection_df_dict[num_seed]\n",
    "    for attack in attack_list:\n",
    "        perf_i = perf_df[(perf_df[attack] == True) & (perf_df[\"Ensemble Level\"] == \"Single Instance\")]\n",
    "        cifar10_auc = perf_i[perf_i[\"dataset\"] == \"cifar10\"][\"AUC\"].values[0]\n",
    "        cifar10_acc = perf_i[perf_i[\"dataset\"] == \"cifar10\"][\"ACC\"].values[0]\n",
    "        cifar100_auc = perf_i[perf_i[\"dataset\"] == \"cifar100\"][\"AUC\"].values[0]\n",
    "        cifar100_acc = perf_i[perf_i[\"dataset\"] == \"cifar100\"][\"ACC\"].values[0]\n",
    "        cinic10_auc = perf_i[perf_i[\"dataset\"] == \"cinic10\"][\"AUC\"].values[0]\n",
    "        cinic10_acc = perf_i[perf_i[\"dataset\"] == \"cinic10\"][\"ACC\"].values[0]\n",
    "        texas100_auc = perf_i[perf_i[\"dataset\"] == \"texas100\"][\"AUC\"].values[0]\n",
    "        texas100_acc = perf_i[perf_i[\"dataset\"] == \"texas100\"][\"ACC\"].values[0]\n",
    "        purchase100_auc = perf_i[perf_i[\"dataset\"] == \"purchase100\"][\"AUC\"].values[0]\n",
    "        purchase100_acc = perf_i[perf_i[\"dataset\"] == \"purchase100\"][\"ACC\"].values[0]\n",
    "        new_row = pd.DataFrame([{\"Ensemble_level\": \"Single Instances\", \"attack\": attack, \n",
    "                                 \"cifar10_auc\": cifar10_auc, \"cifar10_acc\": cifar10_acc, \n",
    "                                 \"cifar100_auc\": cifar100_auc, \"cifar100_acc\": cifar100_acc,\n",
    "                                 \"cinic10_auc\": cinic10_auc, \"cinic10_acc\": cinic10_acc, \n",
    "                                 \"texas100_auc\": texas100_auc, \"texas100_acc\": texas100_acc,\n",
    "                                   \"purchase100_auc\": purchase100_auc, \"purchase100_acc\": purchase100_acc}])\n",
    "                \n",
    "        result_df = pd.concat([result_df, new_row], ignore_index=True)\n",
    "\n",
    "    # handle rows for multi attack, preserving only the multi attack with all 4 attacks\n",
    "    perf_df = perf_union_df_dict[num_seed] if ensemble_method == \"union\" else perf_intersection_df_dict[num_seed]\n",
    "    \n",
    "    perf_i = perf_df[(perf_df[\"Ensemble Level\"] == \"Multi Attacks\") & (perf_df[\"losstraj\"] == True) & (perf_df[\"reference\"] == True) & (perf_df[\"lira\"] == True) & (perf_df[\"calibration\"] == True)]\n",
    "    cifar10_auc = perf_i[perf_i[\"dataset\"] == \"cifar10\"][\"AUC\"].values[0]\n",
    "    cifar10_acc = perf_i[perf_i[\"dataset\"] == \"cifar10\"][\"ACC\"].values[0]\n",
    "    cifar100_auc = perf_i[perf_i[\"dataset\"] == \"cifar100\"][\"AUC\"].values[0]\n",
    "    cifar100_acc = perf_i[perf_i[\"dataset\"] == \"cifar100\"][\"ACC\"].values[0]\n",
    "    cinic10_auc = perf_i[perf_i[\"dataset\"] == \"cinic10\"][\"AUC\"].values[0]\n",
    "    cinic10_acc = perf_i[perf_i[\"dataset\"] == \"cinic10\"][\"ACC\"].values[0]\n",
    "    texas100_auc = perf_i[perf_i[\"dataset\"] == \"texas100\"][\"AUC\"].values[0]\n",
    "    texas100_acc = perf_i[perf_i[\"dataset\"] == \"texas100\"][\"ACC\"].values[0]\n",
    "    purchase100_auc = perf_i[perf_i[\"dataset\"] == \"purchase100\"][\"AUC\"].values[0]\n",
    "    purchase100_acc = perf_i[perf_i[\"dataset\"] == \"purchase100\"][\"ACC\"].values[0]\n",
    "\n",
    "    new_row = pd.DataFrame([{\"Ensemble_level\": \"Multi Attack\", \"attack\": \"All\",\n",
    "                                \"cifar10_auc\": cifar10_auc, \"cifar10_acc\": cifar10_acc, \n",
    "                                \"cifar100_auc\": cifar100_auc, \"cifar100_acc\": cifar100_acc,\n",
    "                                \"cinic10_auc\": cinic10_auc, \"cinic10_acc\": cinic10_acc, \n",
    "                                \"texas100_auc\": texas100_auc, \"texas100_acc\": texas100_acc,\n",
    "                                \"purchase100_auc\": purchase100_auc, \"purchase100_acc\": purchase100_acc}])\n",
    "    \n",
    "    result_df = pd.concat([result_df, new_row], ignore_index=True)\n",
    "\n",
    "    # save to csv\n",
    "    result_df.to_csv(f\"{path_to_save_result}/{ensemble_method}_{num_seed}seed_perf_comp_multi_datasets.csv\", index=False)\n",
    "    print(f\"Saved to {path_to_save_result}/{ensemble_method}_{num_seed}seed_perf_comp_multi_datasets.csv\")\n",
    "\n",
    "\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
